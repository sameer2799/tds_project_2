{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import sys\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"AIPROXY_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_request(json):\n",
    "    url = \"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Make the request\n",
    "    req = requests.post(url, headers=headers, json=json)\n",
    "    # Response body\n",
    "    res = req.json()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  request_to_llm_for_metadata(token, system_prompt: str, sample_data: str):\n",
    "    '''\n",
    "    Make a request only for analysis prompt\n",
    "    '''\n",
    "\n",
    "    url = \"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    # Response schema of data\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"columns\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"List of column names and their respective types\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"column_name\": {\"type\": \"string\", \"description\": \"Column name\"},\n",
    "                        \"column_type\": {\"type\": \"string\", \"description\": \"Column type\"},\n",
    "                        \n",
    "                    },\n",
    "                    \"required\": [\"column_name\", \"column_type\"],\n",
    "                },\n",
    "                \"minItems\": 1,\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"columns\"],\n",
    "    }\n",
    "\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"data_schema\",\n",
    "            \"description\": \"Extract column name and the type from a CSV file to process later in python\",\n",
    "            \"parameters\": schema,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # JSON payload\n",
    "    json = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"functions\": functions,\n",
    "        \"function_call\": {\"name\": \"data_schema\"},\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": sample_data,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    req = requests.post(url, headers=headers, json=json)\n",
    "    # Response body\n",
    "    res = req.json()\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "        \"You are an expert at data analysis.\"\n",
    "        \"You are going to study the sample data provided, return the column names and their respective types in json format;\"\n",
    "        \"use function data_schema.The first row will be names and rest data.\"\n",
    "        \"Be robust, figure out the type by majority vote, cross-check by name of column, ignore empty cells.\"\n",
    "        \"The data may or may not be clean. Possible types are: 'integer', 'float', 'object', 'boolean', 'date' and 'url'.\"\n",
    "    )\n",
    "    \n",
    "with open(\"happiness/happiness.csv\", \"r\") as f:\n",
    "    sample_data = ''.join([f.readline() for i in range(5)])\n",
    "    \n",
    "# Sending request to LLM\n",
    "res = request_to_llm_for_metadata(token = token, system_prompt = prompt, sample_data = sample_data)\n",
    "# Response from LLM received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Aez8Lwef19KNbv0T3XPHxUKSQUXUL',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1734331481,\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': None,\n",
       "    'function_call': {'name': 'data_schema',\n",
       "     'arguments': '{\"columns\":[{\"column_name\":\"Country name\",\"column_type\":\"object\"},{\"column_name\":\"year\",\"column_type\":\"integer\"},{\"column_name\":\"Life Ladder\",\"column_type\":\"float\"},{\"column_name\":\"Log GDP per capita\",\"column_type\":\"float\"},{\"column_name\":\"Social support\",\"column_type\":\"float\"},{\"column_name\":\"Healthy life expectancy at birth\",\"column_type\":\"float\"},{\"column_name\":\"Freedom to make life choices\",\"column_type\":\"float\"},{\"column_name\":\"Generosity\",\"column_type\":\"float\"},{\"column_name\":\"Perceptions of corruption\",\"column_type\":\"float\"},{\"column_name\":\"Positive affect\",\"column_type\":\"float\"},{\"column_name\":\"Negative affect\",\"column_type\":\"float\"}]}'},\n",
       "    'refusal': None},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 403,\n",
       "  'completion_tokens': 135,\n",
       "  'total_tokens': 538,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'system_fingerprint': 'fp_6fc10e10eb',\n",
       " 'monthlyCost': 0.08165999999999998,\n",
       " 'cost': 0.002019,\n",
       " 'monthlyRequests': 50}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = json.loads(res['choices'][0]['message']['function_call']['arguments'])['columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'column_name': 'Country name', 'column_type': 'object'},\n",
       " {'column_name': 'year', 'column_type': 'integer'},\n",
       " {'column_name': 'Life Ladder', 'column_type': 'float'},\n",
       " {'column_name': 'Log GDP per capita', 'column_type': 'float'},\n",
       " {'column_name': 'Social support', 'column_type': 'float'},\n",
       " {'column_name': 'Healthy life expectancy at birth', 'column_type': 'float'},\n",
       " {'column_name': 'Freedom to make life choices', 'column_type': 'float'},\n",
       " {'column_name': 'Generosity', 'column_type': 'float'},\n",
       " {'column_name': 'Perceptions of corruption', 'column_type': 'float'},\n",
       " {'column_name': 'Positive affect', 'column_type': 'float'},\n",
       " {'column_name': 'Negative affect', 'column_type': 'float'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLM_analysis(prompt, meta):\n",
    "    json = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": meta,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "\n",
    "    res= base_request(json)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = (\"You are given a metadata containing column names and their types. You are expert data analyst.\"\n",
    "      \"Study the columns and types, perform various complex analysis carefully (for example: correlation matrix or heatmap is error-prone for non-numeric columns)\"\n",
    "      \"Dont write code for reading data. I will pass data in variable 'df'.\"\n",
    "      \"The code should be robust for any type of data sent.\"\n",
    "      \"Don't print to stdout and charts should be generated in png format instead of printing.\"\n",
    "      \"Code should not be a function.\"\n",
    "      \"Return only python code for the analysis no string quoted or backticks, pure python. The code should generate some charts (1 or 3 max).\"\n",
    "      )\n",
    "\n",
    "response = LLM_analysis(pr, json.dumps(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Generate a heatmap for the correlation matrix\n",
      "correlation_matrix = df.corr()\n",
      "plt.figure(figsize=(12, 10))\n",
      "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
      "plt.title('Correlation Matrix Heatmap')\n",
      "plt.savefig('correlation_matrix_heatmap.png')\n",
      "\n",
      "# Boxplot to visualize the distribution of 'Life Ladder' across different countries\n",
      "plt.figure(figsize=(15, 8))\n",
      "sns.boxplot(x='Country name', y='Life Ladder', data=df)\n",
      "plt.xticks(rotation=90)\n",
      "plt.title('Boxplot of Life Ladder by Country')\n",
      "plt.savefig('boxplot_life_ladder_by_country.png')\n",
      "\n",
      "# Line plot for Life Ladder over the years\n",
      "plt.figure(figsize=(12, 6))\n",
      "mean_life_ladder = df.groupby('year')['Life Ladder'].mean().reset_index()\n",
      "sns.lineplot(x='year', y='Life Ladder', data=mean_life_ladder, marker='o')\n",
      "plt.title('Average Life Ladder Over Years')\n",
      "plt.savefig('average_life_ladder_over_years.png')\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "with open('happiness/happiness.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "results = []\n",
    "    \n",
    "df = pd.read_csv('happiness/happiness.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Afghanistan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:5\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Afghanistan'"
     ]
    }
   ],
   "source": [
    "exec(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\"\n",
    "    \n",
    "headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    \n",
    "\n",
    "def correct_error_LLM_request(original_prompt, error_in_response_to_correct):\n",
    "    \n",
    "    json = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": original_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": error_in_response_to_correct,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Some error occurred. Correct only the erroneous part.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    res = requests.post(url=url, headers=headers, json=json)\n",
    "    return res.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    exec(response['choices'][0]['message']['content'])\n",
    "    flag=1\n",
    "except:\n",
    "    corrected_response = correct_error_LLM_request(pr, response['choices'][0]['message']['content'])\n",
    "    flag=0\n",
    "    \n",
    "if flag:\n",
    "    print(\"Original Ran...\")\n",
    "else:\n",
    "    print(\"Corrected response..\")\n",
    "    print(corrected_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Generate a heatmap for the correlation matrix, only for numeric columns\n",
      "correlation_matrix = df.select_dtypes(include=['float64', 'int64']).corr()\n",
      "plt.figure(figsize=(12, 10))\n",
      "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
      "plt.title('Correlation Matrix Heatmap')\n",
      "plt.savefig('correlation_matrix_heatmap.png')\n",
      "\n",
      "# Boxplot to visualize the distribution of 'Life Ladder' across different countries\n",
      "plt.figure(figsize=(15, 8))\n",
      "sns.boxplot(x='Country name', y='Life Ladder', data=df)\n",
      "plt.xticks(rotation=90)\n",
      "plt.title('Boxplot of Life Ladder by Country')\n",
      "plt.savefig('boxplot_life_ladder_by_country.png')\n",
      "\n",
      "# Line plot for Life Ladder over the years\n",
      "plt.figure(figsize=(12, 6))\n",
      "mean_life_ladder = df.groupby('year')['Life Ladder'].mean().reset_index()\n",
      "sns.lineplot(x='year', y='Life Ladder', data=mean_life_ladder, marker='o')\n",
      "plt.title('Average Life Ladder Over Years')\n",
      "plt.savefig('average_life_ladder_over_years.png')\n"
     ]
    }
   ],
   "source": [
    "print(corrected_response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(corrected_response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_README(system_prompt, metadata, base64_images_list):\n",
    "    # Create the API request payload\n",
    "    json = {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\" : \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": metadata,\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    # Adding all images provided to json payload\n",
    "    for image in base64_images_list:\n",
    "        image_object = {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"detail\": \"low\",\n",
    "                \"url\": f'data:image/jpeg;base64,{image}'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        json['messages'][1][\"content\"].append(image_object)\n",
    "\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.post(url, headers=headers, json=json)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-Af0GaiymNF7d7llpavfNNwZB08gC1', 'object': 'chat.completion', 'created': 1734335836, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"# README: Analysis of Country Well-being Indicators \\n\\n## Overview\\nThis README summarizes the analysis of a dataset containing well-being indicators across various countries. The dataset includes multiple variables, such as Life Ladder scores, GDP per capita, social support, and health metrics, recorded over several years. The primary objective of the analysis was to uncover trends and relationships between these indicators and their implications for policy-making.\\n\\n## Dataset Description\\nThe dataset consists of the following columns:\\n\\n- **Country name**: Identifies each country (object type).\\n- **Year**: The year of observation (integer type).\\n- **Life Ladder**: A subjective measure of well-being or happiness (float type).\\n- **Log GDP per capita**: Natural logarithm of GDP per capita (float type).\\n- **Social support**: Measure of support available to individuals (float type).\\n- **Healthy life expectancy at birth**: Average number of years an individual is expected to live in good health (float type).\\n- **Freedom to make life choices**: Perception of freedom in life decisions (float type).\\n- **Generosity**: Citizens' willingness to give (float type).\\n- **Perceptions of corruption**: Views on corruption within the government and businesses (float type).\\n- **Positive affect**: Score measuring experiences of positive emotions (float type).\\n- **Negative affect**: Score measuring experiences of negative emotions (float type).\\n\\n## Analysis Conducted\\n1. **Correlation Matrix**: A heatmap was generated to identify relationships between the various well-being indicators. Strong correlations were observed between:\\n   - Life Ladder and Log GDP per capita.\\n   - Life Ladder and Social support.\\n   - Life Ladder and Healthy life expectancy at birth.\\n\\n2. **Boxplot Analysis**: A boxplot representing the distribution of Life Ladder scores across different countries was created. This visualization highlighted disparities in well-being between countries, as well as potential outliers.\\n\\n3. **Trend Analysis**: A line chart illustrated the average Life Ladder scores over the years, revealing a notable decline in 2005, followed by gradual recovery and fluctuations in subsequent years.\\n\\n## Insights Discovered\\n- **Significant Predictors of Well-being**: Higher Log GDP per capita and stronger social support are correlated with higher Life Ladder scores, indicating that economic and social factors play crucial roles in individual well-being.\\n- **Country Disparities**: The boxplot reveals substantial variation in Life Ladder scores among countries, suggesting that local policies and initiatives significantly influence well-being.\\n- **Temporal Trends**: The average well-being score experienced a dip in 2005 but showed stability and slight growth afterward, indicating resilience or recovery in the population’s perception of well-being.\\n\\n## Implications of Findings\\n- **Policy Recommendations**: Governments should focus on enhancing social support systems and fostering economic growth to improve citizens' well-being. Programs that increase individual freedom and reduce perceived corruption can also contribute positively.\\n- **Focus on Disparities**: Countries exhibiting low Life Ladder scores must investigate underlying causes and implement targeted interventions to boost overall well-being.\\n- **Continued Monitoring**: Regular assessment of these well-being indicators is essential for understanding their evolution and informing policy over time, ensuring that interventions remain effective and relevant.\\n\\nThis analysis emphasizes the interplay between economic, social, and personal factors in shaping well-being and offers pathways for actionable policy improvements.\", 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 8769, 'completion_tokens': 677, 'total_tokens': 9446, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'system_fingerprint': 'fp_39a40c96a0', 'monthlyCost': 0.208641, 'cost': 0.030369, 'monthlyRequests': 74}\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory path\n",
    "directory_path = \"/workspaces/tds_project_2/\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(directory_path)\n",
    "\n",
    "# Filter the list to only include PNG files\n",
    "png_files = [file for file in files if file.endswith(\".png\")]\n",
    "final_images = []\n",
    "# Read each PNG file\n",
    "for file in png_files:\n",
    "    # Read the image file as binary data\n",
    "    with open(file, 'rb') as image_file:\n",
    "        image_data = image_file.read()\n",
    "\n",
    "    # Encode the image data to base64\n",
    "    base64_image = base64.b64encode(image_data).decode('utf-8')\n",
    "    final_images.append(base64_image)\n",
    "\n",
    "pr = (\"You are an expert data analyst. You are a given the columns and the column types of a csv dataset.\"\n",
    "      \"You are also given some images of analysis already done by me.\"\n",
    "      \"Describe in detail: \"\n",
    "      \"- The data you received, briefly\"\n",
    "      \"- The analysis you carried out\"\n",
    "      \"- The insights you discovered\"\n",
    "      \"- The implications of your findings (i.e. what to do with the insights)\"\n",
    "      \"You need to generate a professional README file ONLY.\"\n",
    ")\n",
    "\n",
    "README_response = generate_README(pr, json.dumps(metadata), final_images)\n",
    "print(README_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated README saved...\n"
     ]
    }
   ],
   "source": [
    "generated_file = README_response['choices'][0]['message']['content']\n",
    "# Save the generated image to a file\n",
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(generated_file)\n",
    "    print(\"Generated README saved...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     \"base64\",\n",
    "\n",
    "#     \"shutil\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual analysis\n",
    "import chardet\n",
    "\n",
    "def analyze_data(file_path, metadata):\n",
    "    # Detect encoding\n",
    "    with open('happiness/happiness.csv', 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        encoding = result['encoding']\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    df = pd.read_csv(file_path, encoding=encoding)\n",
    "    category_cols = [x['column_name'] for x in metadata if x['column_type'] == 'object']\n",
    "    numeric_cols = [x['column_name'] for x in metadata if x['column_type'] in ['integer', 'float']]\n",
    "    # Find missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "\n",
    "    missing = (\"Missing Values per Column\", missing_values[missing_values > 0])\n",
    "    results.append(missing)\n",
    "\n",
    "\n",
    "    # Detect outliers using z-score (for numerical columns only)\n",
    "    numeric_df = df[numeric_cols]\n",
    "    z_scores = numeric_df.apply(zscore).abs()\n",
    "    outliers = (z_scores > 3).sum()\n",
    "\n",
    "    outlier = (\"Outliers per Numeric Column\", outliers[outliers > 0])\n",
    "    results.append(outlier)\n",
    "    # Summary statistics\n",
    "    summary = (\"Summary Statistics\", df.describe())\n",
    "    results.append(summary)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
